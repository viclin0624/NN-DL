# 前言
* 机器学习问题：从有限样例中通过算法总结出一般性的规律，并可以应用到新的未知数据里
* 贡献度分配问题（Credit Assignment Problem）：输出结果中每个组件的贡献是多少
# 1.1 人工智能
* 人工智能（Artificial Intelligence）：让机器具有人类的智能
* 人工智能的主要领域：
  * 感知
  * 学习
  * 认知
## 1.1.1 人工智能的发展历史
1. 推理期：1956达特茅斯会议之后
2. 知识期：20世纪70年代，专家系统
3. 学习期：1985年，神经网络重新流行，机器学习算法
## 1.1.2 人工智能的流派
* 符号主义
* 连接主义
# 1.2 机器学习
1. 数据预处理
2. 特征提取：例如尺度不变特征变换（Scale Invariant Feature Transform）
3. 特征转换：PCA LDA
 * 降维：特征抽取（Feature Extraction），特征选择（Feature Selection）
 * 升维
4. 预测
# 1.3 表示学习
* 什么是一个好的表示
* 如何学习到好的表示
## 1.3.1 局部表示和分布式表示
1. 具有很强的表示能力
2. 使后续的学习任务变得简单
3. 具有一般性
* 局部表示：one-hot向量
* 解释性好
* 特征组合后通常是稀疏的二值向量
* 维数很高，不能扩展
* 无法衡量相似度
* 分布式表示：Embedding，例如RGB
## 1.3.2 表示学习
# 1.4 深度学习
端到端学习：避免了单独优化模块，无法全局最优的；避免了前一步的错误会对后续的模型造成很大的影响 
# 1.5 神经网络
## 1.5.1 人脑神经网络
当神经元A的一个轴突和神经元B**很近**，足以对它产生影响，并且持续地，重复地，参与了对神经元B的兴奋，那么在这两个神经元或其中之一会发生某种生长过程或新陈代谢变化，以致神经元A作为能使神经元B兴奋的细胞之一，它的效能加强了。——赫布理论  
**相关联**地收到刺激的神经元突触强度增加  
**短期记忆**重复足够多的次数变成**长期记忆**  
（用手肘磕桌子会感到痛，为什么不会形成手肘向下挥就会痛的机制？人脑在判断相关性之外，是否也能判断因果性？例如不会认为痛是因为向下挥手肘，而是因为向下挥手肘会磕到桌子）
## 1.5.2 人工神经网络
ANN难以学习——首个具有学习能力的赫布网络——机器学习思想的感知器——反向传播算法  
塑造复杂函数的能力：网络容量
## 1.5.3 神经网络的发展历史
第一阶段：模型提出 1943-1969  
第二阶段：冰河期 1969-1983 BP  
第三阶段：BP算法引起的复兴 1983-1995 Hopfield网络（联想记忆） 玻尔兹曼机（随机化Hopfield网络） 分布式并行处理（Parallel Distributed Processing） 梯度消失问题（两步训练）  
第四阶段：流行度降低 1995-2006 SVM流行  
第五阶段：深度学习的崛起 2006- 逐层预训练学习一个深度信念网络 “预训练+精调”  
# 1.6 本书的知识体系
* 机器学习
* 神经网络
* 概率图模型
# 1.7 常用的深度学习框架
# 1.8 总结和深入阅读
http://cs231n.standford.edu  
http://web.stanford.edu/class/cs224n/  
国际表示学习会议（International Conference on Learning Representations，ICLR）  
神经信息处理系统年会（Annual Conference on Neural Information Processing Systems，NeurIPS）  
国际机器学习会议（International Conference on Machine Learning， ICML）  
国际人工智能联合会议（International Joint Conference on Artificial Intelligence，IJCAI）  
美国人工智能协会年会（AAAI Conference on Artificial Intelligence， AAAI）  
CV：CVPR ICCV  
NLP：ACL EMNLP  
